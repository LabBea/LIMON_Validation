---
title: "Network Testing - Sensitivity of Number of Subjects"
output: html_notebook
---

Here test the strength of recovery of edges of the networks for 0 inflated and non-0 inflated data


# 1. Load Library
*** 

```{r}
library(tidyverse)
library(igraph)
library(NBZIMM)
library(SpiecEasi)
library(LIMON)
library(here)
library(lme4)
library(Matrix)
library(tscount)
library(patchwork)
library(MASS)
library(matrixcalc)
library(gridExtra)
library(devtools)
library(miaSim)
library(reshape2)
library(ggpubr)
```



# 2. Non-0 Data (NBLMM LIMON Model)
***


## 2.1 - Subjects N=10

__LIMON Data__  
Make LIMON Object
```{r}
SimData <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N10.csv"))
SimData <- column_to_rownames(SimData, "X")

# metadata
meta_data <- SimData[,1:5]
meta_data$Time <- as.numeric(meta_data$Time)
meta_data$BMI <- as.numeric(meta_data$BMI)
meta_data$Age <- as.numeric(meta_data$Age)

# Shorten to 3 timepoints to run faster
limon_meta <- meta_data %>% filter(Time %in% c(1,2,3))

# Count data
limon_counts <- as.matrix(SimData[,6:55])

# sort rows
limon_counts <- limon_counts[rownames(limon_meta),]

  
L_obj <- LIMON_Obj(Counts = limon_counts, 
                           SampleData = limon_meta)
```


Distribution Fitting and check
```{r}
# Set seed
set.seed(12345)
# Fit the distribution/remove covariates
#################################################################################
L_obj2 <- LIMON_DistrFit(Obj = L_obj, 
                           prop.data = FALSE,
                           Time = "Time", 
                           Subject = "ID", 
                           Covariates = c("Sex", "BMI", "Age"),
                           model = "Sex+BMI+Age",
                           use_zinb = FALSE)


# Check the taxa now
#################################################################################
plot_data <- merge(limon_meta, L_obj2[["Corrected_Counts"]], by = 0, all=TRUE)
plot_data <- column_to_rownames(plot_data, "Row.names")

# Correlation matrix
cor_limon <- cor((plot_data[,6:55]), method = "spearman")
heatmap(cor_limon, Colv = NA, Rowv = NA, main = "Correlation after NBLMM")

# Correlation matrix
cor_raw <- cor((SimData[,6:55]), method = "spearman")
heatmap(cor_raw, Colv = NA, Rowv = NA, main = "Correlation of Original Data")

#Frobenius Norm
cov_change <- cor_raw - cor_limon
norm(cov_change, type = "F")
```


Networks of LIMON Data
```{r}
# Set seed
pseed <- list(rep.num=50, seed=10010)

# SPIEC-EASI per time
L_obj3 <- LIMON_NetInf_Time(Obj = L_obj2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj4 <- LIMON_Edges_Networks(L_obj3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, 
                                       vertex.label.color = "black")
```


__Raw Data__  
Networks of the Raw Data with covariates
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_N10.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim4 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```


__Raw Data + no covariates__  
Networks of the Raw Data with covariates (no correction)
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N10.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim5 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```


Calculate the similar edges across the three data types
```{r}
# LIMON Data - Extract Edges
################################################################################
L_Edges_T1 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_1"]])
L_Edges_T1 <- L_Edges_T1 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T1$Time <- 1

L_Edges_T2 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_2"]])
L_Edges_T2 <- L_Edges_T2 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T2$Time <- 2

L_Edges_T3 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_3"]])
L_Edges_T3 <- L_Edges_T3 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T3$Time <- 3

# Original Data + Cov - Extract edges
################################################################################
Cov_Edges_T1 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_1"]])
Cov_Edges_T1 <- Cov_Edges_T1 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T1$Time <- 1

Cov_Edges_T2 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_2"]])
Cov_Edges_T2 <- Cov_Edges_T2 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T2$Time <- 2

Cov_Edges_T3 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_3"]])
Cov_Edges_T3 <- Cov_Edges_T3 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T3$Time <- 3

# Original Data - Extract Edges
################################################################################
O_Edges_T1 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_1"]])
O_Edges_T1 <- O_Edges_T1 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T1$Time <- 1

#Blank graph so remove
#O_Edges_T2 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_2"]])
#O_Edges_T2 <- O_Edges_T2 %>% rename("Edge_weight" = "O_Edge_weight")
#O_Edges_T2$Time <- 2

O_Edges_T3 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_3"]])
O_Edges_T3 <- O_Edges_T3 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T3$Time <- 3

# Comparison Graph Data
################################################################################

#Summary Data Time 1 ######################
Merged_T1 <- merge(L_Edges_T1, O_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T1 <- merge(Merged_T1, Cov_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T1$Recovery <- ifelse(
  !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
  (Merged_T1$L_Edge_weight != 0 & Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
    (Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) &
      ((Merged_T1$L_Edge_weight > 0 & Merged_T1$O_Edge_weight > 0) | 
       (Merged_T1$L_Edge_weight < 0 & Merged_T1$O_Edge_weight < 0)), 1, 0
    )
  )
)

#Summary Data Time 2 ######################
# blank O_Edges_T2, add in as NQ
#Merged_T2 <- merge(L_Edges_T2, O_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2 <- merge(L_Edges_T2, Cov_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2$O_Edge_weight <- NA

Merged_T2$Recovery <- ifelse(
  !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
  (Merged_T2$L_Edge_weight != 0 & Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
    (Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) &
      ((Merged_T2$L_Edge_weight > 0 & Merged_T2$O_Edge_weight > 0) | 
       (Merged_T2$L_Edge_weight < 0 & Merged_T2$O_Edge_weight < 0)), 1, 0
    )
  )
)


#Summary Data Time 3 ######################
Merged_T3 <- merge(L_Edges_T3, O_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T3 <- merge(Merged_T3, Cov_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T3$Recovery <- ifelse(
  !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
  (Merged_T3$L_Edge_weight != 0 & Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
    (Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) &
      ((Merged_T3$L_Edge_weight > 0 & Merged_T3$O_Edge_weight > 0) | 
       (Merged_T3$L_Edge_weight < 0 & Merged_T3$O_Edge_weight < 0)), 1, 0
    )
  )
)


# Merge together
################################################################################
Merged_T1 <- rbind(Merged_T1, Merged_T2, Merged_T3)
Merged_T1$SampleSize <- 10

```





## 2.2 - Subjects N=20

__LIMON Data__  
Make LIMON Object
```{r}
SimData <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N20.csv"))
SimData <- column_to_rownames(SimData, "X")

# metadata
meta_data <- SimData[,1:5]
meta_data$Time <- as.numeric(meta_data$Time)
meta_data$BMI <- as.numeric(meta_data$BMI)
meta_data$Age <- as.numeric(meta_data$Age)

# Shorten to 3 timepoints to run faster
limon_meta <- meta_data %>% filter(Time %in% c(1,2,3))

# Count data
limon_counts <- as.matrix(SimData[,6:55])

# sort rows
limon_counts <- limon_counts[rownames(limon_meta),]

  
L_obj <- LIMON_Obj(Counts = limon_counts, 
                           SampleData = limon_meta)
```


Distribution Fitting and check
```{r}
# Set seed
set.seed(12345)
# Fit the distribution/remove covariates
#################################################################################
L_obj2 <- LIMON_DistrFit(Obj = L_obj, 
                           prop.data = FALSE,
                           Time = "Time", 
                           Subject = "ID", 
                           Covariates = c("Sex", "BMI", "Age"),
                           model = "Sex+BMI+Age",
                           use_zinb = FALSE)


# Check the taxa now
#################################################################################
plot_data <- merge(limon_meta, L_obj2[["Corrected_Counts"]], by = 0, all=TRUE)
plot_data <- column_to_rownames(plot_data, "Row.names")

# Correlation matrix
cor_limon <- cor((plot_data[,6:55]), method = "spearman")
heatmap(cor_limon, Colv = NA, Rowv = NA, main = "Correlation after NBLMM")

# Correlation matrix
cor_raw <- cor((SimData[,6:55]), method = "spearman")
heatmap(cor_raw, Colv = NA, Rowv = NA, main = "Correlation of Original Data")

#Frobenius Norm
cov_change <- cor_raw - cor_limon
norm(cov_change, type = "F")
```


Networks of LIMON Data
```{r}
# Set seed
pseed <- list(rep.num=50, seed=10010)

# SPIEC-EASI per time
L_obj3 <- LIMON_NetInf_Time(Obj = L_obj2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj4 <- LIMON_Edges_Networks(L_obj3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, 
                                       vertex.label.color = "black")
```

__Raw Data no Covariates__  
Networks of the Raw Data 
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_N20.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim4 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```



__Raw Data + Covariates__  
Networks of the Raw Data with covariates (no correction)
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N20.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim5 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```


Calculate the similar edges across the three data types
```{r}
# LIMON Data - Extract Edges
################################################################################
L_Edges_T1 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_1"]])
L_Edges_T1 <- L_Edges_T1 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T1$Time <- 1

L_Edges_T2 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_2"]])
L_Edges_T2 <- L_Edges_T2 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T2$Time <- 2

L_Edges_T3 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_3"]])
L_Edges_T3 <- L_Edges_T3 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T3$Time <- 3

# Original Data + Cov - Extract edges
################################################################################
Cov_Edges_T1 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_1"]])
Cov_Edges_T1 <- Cov_Edges_T1 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T1$Time <- 1

Cov_Edges_T2 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_2"]])
Cov_Edges_T2 <- Cov_Edges_T2 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T2$Time <- 2

Cov_Edges_T3 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_3"]])
Cov_Edges_T3 <- Cov_Edges_T3 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T3$Time <- 3

# Original Data - Extract Edges
################################################################################
O_Edges_T1 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_1"]])
O_Edges_T1 <- O_Edges_T1 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T1$Time <- 1

O_Edges_T2 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_2"]])
O_Edges_T2 <- O_Edges_T2 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T2$Time <- 2

O_Edges_T3 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_3"]])
O_Edges_T3 <- O_Edges_T3 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T3$Time <- 3

# Comparison Graph Data
################################################################################

#Summary Data Time 1 ######################
Merged_T1 <- merge(L_Edges_T1, O_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T1 <- merge(Merged_T1, Cov_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T1$Recovery <- ifelse(
  !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
  (Merged_T1$L_Edge_weight != 0 & Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
    (Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) &
      ((Merged_T1$L_Edge_weight > 0 & Merged_T1$O_Edge_weight > 0) | 
       (Merged_T1$L_Edge_weight < 0 & Merged_T1$O_Edge_weight < 0)), 1, 0
    )
  )
)

#Summary Data Time 2 ######################
Merged_T2 <- merge(L_Edges_T2, O_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2 <- merge(Merged_T2, Cov_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T2$Recovery <- ifelse(
  !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
  (Merged_T2$L_Edge_weight != 0 & Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
    (Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) &
      ((Merged_T2$L_Edge_weight > 0 & Merged_T2$O_Edge_weight > 0) | 
       (Merged_T2$L_Edge_weight < 0 & Merged_T2$O_Edge_weight < 0)), 1, 0
    )
  )
)


#Summary Data Time 3 ######################
Merged_T3 <- merge(L_Edges_T3, O_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T3 <- merge(Merged_T3, Cov_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T3$Recovery <- ifelse(
  !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
  (Merged_T3$L_Edge_weight != 0 & Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
    (Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) &
      ((Merged_T3$L_Edge_weight > 0 & Merged_T3$O_Edge_weight > 0) | 
       (Merged_T3$L_Edge_weight < 0 & Merged_T3$O_Edge_weight < 0)), 1, 0
    )
  )
)


# Merge together
################################################################################
Merged_T20 <- rbind(Merged_T1, Merged_T2, Merged_T3)
Merged_T20$SampleSize <- 20

```



## 2.3 - Subjects N=50

__LIMON Data__  
Make LIMON Object
```{r}
SimData <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N50.csv"))
SimData <- column_to_rownames(SimData, "X")

# metadata
meta_data <- SimData[,1:5]
meta_data$Time <- as.numeric(meta_data$Time)
meta_data$BMI <- as.numeric(meta_data$BMI)
meta_data$Age <- as.numeric(meta_data$Age)

# Shorten to 3 timepoints to run faster
limon_meta <- meta_data %>% filter(Time %in% c(1,2,3))

# Count data
limon_counts <- as.matrix(SimData[,6:55])

# sort rows
limon_counts <- limon_counts[rownames(limon_meta),]

  
L_obj <- LIMON_Obj(Counts = limon_counts, 
                           SampleData = limon_meta)
```


Distribution Fitting and check
```{r}
# Set seed
set.seed(12345)
# Fit the distribution/remove covariates
#################################################################################
L_obj2 <- LIMON_DistrFit(Obj = L_obj, 
                           prop.data = FALSE,
                           Time = "Time", 
                           Subject = "ID", 
                           Covariates = c("Sex", "BMI", "Age"),
                           model = "Sex+BMI+Age",
                           use_zinb = FALSE)


# Check the taxa now
#################################################################################
plot_data <- merge(limon_meta, L_obj2[["Corrected_Counts"]], by = 0, all=TRUE)
plot_data <- column_to_rownames(plot_data, "Row.names")

# Correlation matrix
cor_limon <- cor((plot_data[,6:55]), method = "spearman")
heatmap(cor_limon, Colv = NA, Rowv = NA, main = "Correlation after NBLMM")

# Correlation matrix
cor_raw <- cor((SimData[,6:55]), method = "spearman")
heatmap(cor_raw, Colv = NA, Rowv = NA, main = "Correlation of Original Data")

#Frobenius Norm
cov_change <- cor_raw - cor_limon
norm(cov_change, type = "F")
```


Networks of LIMON Data
```{r}
# Set seed
pseed <- list(rep.num=50, seed=10010)

# SPIEC-EASI per time
L_obj3 <- LIMON_NetInf_Time(Obj = L_obj2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj4 <- LIMON_Edges_Networks(L_obj3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, 
                                       vertex.label.color = "black")
```

__Raw Data no Covariates__  
Networks of the Raw Data with no covariates
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_N50.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim4 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```




__Raw Data + Covariates__  
Networks of the Raw Data with covariates (no correction)
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N50.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim5 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```



Calculate the similar edges across the three data types
```{r}
# LIMON Data - Extract Edges
################################################################################
L_Edges_T1 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_1"]])
L_Edges_T1 <- L_Edges_T1 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T1$Time <- 1

L_Edges_T2 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_2"]])
L_Edges_T2 <- L_Edges_T2 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T2$Time <- 2

L_Edges_T3 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_3"]])
L_Edges_T3 <- L_Edges_T3 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T3$Time <- 3

# Original Data + Cov - Extract edges
################################################################################
Cov_Edges_T1 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_1"]])
Cov_Edges_T1 <- Cov_Edges_T1 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T1$Time <- 1

Cov_Edges_T2 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_2"]])
Cov_Edges_T2 <- Cov_Edges_T2 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T2$Time <- 2

Cov_Edges_T3 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_3"]])
Cov_Edges_T3 <- Cov_Edges_T3 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T3$Time <- 3

# Original Data - Extract Edges
################################################################################
O_Edges_T1 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_1"]])
O_Edges_T1 <- O_Edges_T1 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T1$Time <- 1

O_Edges_T2 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_2"]])
O_Edges_T2 <- O_Edges_T2 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T2$Time <- 2

O_Edges_T3 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_3"]])
O_Edges_T3 <- O_Edges_T3 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T3$Time <- 3

# Comparison Graph Data
################################################################################

#Summary Data Time 1 ######################
Merged_T1 <- merge(L_Edges_T1, O_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T1 <- merge(Merged_T1, Cov_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T1$Recovery <- ifelse(
  !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
  (Merged_T1$L_Edge_weight != 0 & Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
    (Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) &
      ((Merged_T1$L_Edge_weight > 0 & Merged_T1$O_Edge_weight > 0) | 
       (Merged_T1$L_Edge_weight < 0 & Merged_T1$O_Edge_weight < 0)), 1, 0
    )
  )
)

#Summary Data Time 2 ######################
Merged_T2 <- merge(L_Edges_T2, O_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2 <- merge(Merged_T2, Cov_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T2$Recovery <- ifelse(
  !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
  (Merged_T2$L_Edge_weight != 0 & Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
    (Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) &
      ((Merged_T2$L_Edge_weight > 0 & Merged_T2$O_Edge_weight > 0) | 
       (Merged_T2$L_Edge_weight < 0 & Merged_T2$O_Edge_weight < 0)), 1, 0
    )
  )
)


#Summary Data Time 3 ######################
Merged_T3 <- merge(L_Edges_T3, O_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T3 <- merge(Merged_T3, Cov_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T3$Recovery <- ifelse(
  !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
  (Merged_T3$L_Edge_weight != 0 & Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
    (Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) &
      ((Merged_T3$L_Edge_weight > 0 & Merged_T3$O_Edge_weight > 0) | 
       (Merged_T3$L_Edge_weight < 0 & Merged_T3$O_Edge_weight < 0)), 1, 0
    )
  )
)


# Merge together
################################################################################
Merged_T50 <- rbind(Merged_T1, Merged_T2, Merged_T3)
Merged_T50$SampleSize <- 50

```





## 2.4 - Subjects N=75

__LIMON Data__  
Make LIMON Object
```{r}
SimData <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N75.csv"))
SimData <- column_to_rownames(SimData, "X")

# metadata
meta_data <- SimData[,1:5]
meta_data$Time <- as.numeric(meta_data$Time)
meta_data$BMI <- as.numeric(meta_data$BMI)
meta_data$Age <- as.numeric(meta_data$Age)

# Shorten to 3 timepoints to run faster
limon_meta <- meta_data %>% filter(Time %in% c(1,2,3))

# Count data
limon_counts <- as.matrix(SimData[,6:55])

# sort rows
limon_counts <- limon_counts[rownames(limon_meta),]

  
L_obj <- LIMON_Obj(Counts = limon_counts, 
                           SampleData = limon_meta)
```


Distribution Fitting and check
```{r}
# Set seed
set.seed(12345)
# Fit the distribution/remove covariates
#################################################################################
L_obj2 <- LIMON_DistrFit(Obj = L_obj, 
                           prop.data = FALSE,
                           Time = "Time", 
                           Subject = "ID", 
                           Covariates = c("Sex", "BMI", "Age"),
                           model = "Sex+BMI+Age",
                           use_zinb = FALSE)


# Check the taxa now
#################################################################################
plot_data <- merge(limon_meta, L_obj2[["Corrected_Counts"]], by = 0, all=TRUE)
plot_data <- column_to_rownames(plot_data, "Row.names")

# Correlation matrix
cor_limon <- cor((plot_data[,6:55]), method = "spearman")
heatmap(cor_limon, Colv = NA, Rowv = NA, main = "Correlation after NBLMM")

# Correlation matrix
cor_raw <- cor((SimData[,6:55]), method = "spearman")
heatmap(cor_raw, Colv = NA, Rowv = NA, main = "Correlation of Original Data")

#Frobenius Norm
cov_change <- cor_raw - cor_limon
norm(cov_change, type = "F")
```


Networks of LIMON Data
```{r}
# Set seed
pseed <- list(rep.num=50, seed=10010)

# SPIEC-EASI per time
L_obj3 <- LIMON_NetInf_Time(Obj = L_obj2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj4 <- LIMON_Edges_Networks(L_obj3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, 
                                       vertex.label.color = "black")
```

__Raw Data no Covariates__  
Networks of the Raw Data with no covariates
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_N75.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim4 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```




__Raw Data + Covariates__  
Networks of the Raw Data with covariates (no correction)
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N75.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim5 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```


Calculate the similar edges across the three data types
```{r}
# LIMON Data - Extract Edges
################################################################################
L_Edges_T1 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_1"]])
L_Edges_T1 <- L_Edges_T1 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T1$Time <- 1

L_Edges_T2 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_2"]])
L_Edges_T2 <- L_Edges_T2 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T2$Time <- 2

L_Edges_T3 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_3"]])
L_Edges_T3 <- L_Edges_T3 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T3$Time <- 3

# Original Data + Cov - Extract edges
################################################################################
Cov_Edges_T1 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_1"]])
Cov_Edges_T1 <- Cov_Edges_T1 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T1$Time <- 1

Cov_Edges_T2 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_2"]])
Cov_Edges_T2 <- Cov_Edges_T2 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T2$Time <- 2

Cov_Edges_T3 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_3"]])
Cov_Edges_T3 <- Cov_Edges_T3 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T3$Time <- 3

# Original Data - Extract Edges
################################################################################
O_Edges_T1 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_1"]])
O_Edges_T1 <- O_Edges_T1 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T1$Time <- 1

O_Edges_T2 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_2"]])
O_Edges_T2 <- O_Edges_T2 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T2$Time <- 2

O_Edges_T3 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_3"]])
O_Edges_T3 <- O_Edges_T3 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T3$Time <- 3

# Comparison Graph Data
################################################################################

#Summary Data Time 1 ######################
Merged_T1 <- merge(L_Edges_T1, O_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T1 <- merge(Merged_T1, Cov_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T1$Recovery <- ifelse(
  !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
  (Merged_T1$L_Edge_weight != 0 & Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
    (Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) &
      ((Merged_T1$L_Edge_weight > 0 & Merged_T1$O_Edge_weight > 0) | 
       (Merged_T1$L_Edge_weight < 0 & Merged_T1$O_Edge_weight < 0)), 1, 0
    )
  )
)

#Summary Data Time 2 ######################
Merged_T2 <- merge(L_Edges_T2, O_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2 <- merge(Merged_T2, Cov_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T2$Recovery <- ifelse(
  !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
  (Merged_T2$L_Edge_weight != 0 & Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
    (Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) &
      ((Merged_T2$L_Edge_weight > 0 & Merged_T2$O_Edge_weight > 0) | 
       (Merged_T2$L_Edge_weight < 0 & Merged_T2$O_Edge_weight < 0)), 1, 0
    )
  )
)


#Summary Data Time 3 ######################
Merged_T3 <- merge(L_Edges_T3, O_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T3 <- merge(Merged_T3, Cov_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T3$Recovery <- ifelse(
  !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
  (Merged_T3$L_Edge_weight != 0 & Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
    (Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) &
      ((Merged_T3$L_Edge_weight > 0 & Merged_T3$O_Edge_weight > 0) | 
       (Merged_T3$L_Edge_weight < 0 & Merged_T3$O_Edge_weight < 0)), 1, 0
    )
  )
)


# Merge together
################################################################################
Merged_T75 <- rbind(Merged_T1, Merged_T2, Merged_T3)
Merged_T75$SampleSize <- 75

```




## 2.5 - Subjects N=100

__LIMON Data__  
Make LIMON Object
```{r}
SimData <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N100.csv"))
SimData <- column_to_rownames(SimData, "X")

# metadata
meta_data <- SimData[,1:5]
meta_data$Time <- as.numeric(meta_data$Time)
meta_data$BMI <- as.numeric(meta_data$BMI)
meta_data$Age <- as.numeric(meta_data$Age)

# Shorten to 3 timepoints to run faster
limon_meta <- meta_data %>% filter(Time %in% c(1,2,3))

# Count data
limon_counts <- as.matrix(SimData[,6:55])

# sort rows
limon_counts <- limon_counts[rownames(limon_meta),]

  
L_obj <- LIMON_Obj(Counts = limon_counts, 
                           SampleData = limon_meta)
```


Distribution Fitting and check
```{r}
# Set seed
set.seed(12345)
# Fit the distribution/remove covariates
#################################################################################
L_obj2 <- LIMON_DistrFit(Obj = L_obj, 
                           prop.data = FALSE,
                           Time = "Time", 
                           Subject = "ID", 
                           Covariates = c("Sex", "BMI", "Age"),
                           model = "Sex+BMI+Age",
                           use_zinb = FALSE)


# Check the taxa now
#################################################################################
plot_data <- merge(limon_meta, L_obj2[["Corrected_Counts"]], by = 0, all=TRUE)
plot_data <- column_to_rownames(plot_data, "Row.names")

# Correlation matrix
cor_limon <- cor((plot_data[,6:55]), method = "spearman")
heatmap(cor_limon, Colv = NA, Rowv = NA, main = "Correlation after NBLMM")

# Correlation matrix
cor_raw <- cor((SimData[,6:55]), method = "spearman")
heatmap(cor_raw, Colv = NA, Rowv = NA, main = "Correlation of Original Data")

#Frobenius Norm
cov_change <- cor_raw - cor_limon
norm(cov_change, type = "F")
```


Networks of LIMON Data
```{r}
# Set seed
pseed <- list(rep.num=50, seed=10010)

# SPIEC-EASI per time
L_obj3 <- LIMON_NetInf_Time(Obj = L_obj2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj4 <- LIMON_Edges_Networks(L_obj3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, 
                                       vertex.label.color = "black")
```


__Raw Data no Covariates__  
Networks of the Raw Data 
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_N100.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim4 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```



__Raw Data + Covariates__  
Networks of the Raw Data with covariates (no correction)
```{r}
# Make fake LIMON Object to Pass to Network Inference Steps
##################################################################################
original_data <- read.csv(here("Data", "GLV_SimData", "Subjects_Data","GLV_Cov_N100.csv"))

# Filter to Time 1
Time1_raw <- original_data %>% filter(Time==1)
Time2_raw <- original_data %>% filter(Time==2)
Time3_raw <- original_data %>% filter(Time==3)

# Remove metadata
Time1_raw <- round(Time1_raw[,6:55])
Time2_raw <- round(Time2_raw[,6:55])
Time3_raw <- round(Time3_raw[,6:55])

# Run SPIEC-EASI
L_obj_sim2 <- L_obj2
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_1"]] <- Time1_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_2"]] <- Time2_raw
L_obj_sim2[["Corrected_Counts_Time"]][["Corrected_Counts_3"]] <- Time3_raw


# Network Inference
##################################################################################
# Set seed
pseed <- list(rep.num=50, seed=10010)
# SPIEC-EASI per time
L_obj_sim3 <- LIMON_NetInf_Time(Obj = L_obj_sim2, 
                                         method = "glasso", 
                                         sel.criterion = "bstars",
                                         lambda.min.ratio = 0.01,
                                         pulsar.select=TRUE, 
                                         pulsar.params=pseed,
                                         nlambda = 50)


# Print Networks
L_obj_sim5 <- LIMON_Edges_Networks(L_obj_sim3, threshold = 0.0002, vertex.size = 3, 
                                       vertex.label.cex = 8, vertex.label.color = "black")



```


Calculate the similar edges across the three data types
```{r}
# LIMON Data - Extract Edges
################################################################################
L_Edges_T1 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_1"]])
L_Edges_T1 <- L_Edges_T1 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T1$Time <- 1

L_Edges_T2 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_2"]])
L_Edges_T2 <- L_Edges_T2 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T2$Time <- 2

L_Edges_T3 <- as.data.frame(L_obj4[["Edge_Table"]][["Edge_Table_3"]])
L_Edges_T3 <- L_Edges_T3 %>% rename("Edge_weight" = "L_Edge_weight")
L_Edges_T3$Time <- 3

# Original Data + Cov - Extract edges
################################################################################
Cov_Edges_T1 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_1"]])
Cov_Edges_T1 <- Cov_Edges_T1 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T1$Time <- 1

Cov_Edges_T2 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_2"]])
Cov_Edges_T2 <- Cov_Edges_T2 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T2$Time <- 2

Cov_Edges_T3 <- as.data.frame(L_obj_sim5[["Edge_Table"]][["Edge_Table_3"]])
Cov_Edges_T3 <- Cov_Edges_T3 %>% rename("Edge_weight" = "Cov_Edge_weight")
Cov_Edges_T3$Time <- 3

# Original Data - Extract Edges
################################################################################
O_Edges_T1 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_1"]])
O_Edges_T1 <- O_Edges_T1 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T1$Time <- 1

O_Edges_T2 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_2"]])
O_Edges_T2 <- O_Edges_T2 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T2$Time <- 2

O_Edges_T3 <- as.data.frame(L_obj_sim4[["Edge_Table"]][["Edge_Table_3"]])
O_Edges_T3 <- O_Edges_T3 %>% rename("Edge_weight" = "O_Edge_weight")
O_Edges_T3$Time <- 3

# Comparison Graph Data
################################################################################

#Summary Data Time 1 ######################
Merged_T1 <- merge(L_Edges_T1, O_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T1 <- merge(Merged_T1, Cov_Edges_T1, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T1$Recovery <- ifelse(
  !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
  (Merged_T1$L_Edge_weight != 0 & Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T1$O_Edge_weight) & !is.na(Merged_T1$Cov_Edge_weight) &
    (Merged_T1$O_Edge_weight != 0 & Merged_T1$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T1$L_Edge_weight) & !is.na(Merged_T1$O_Edge_weight) &
      ((Merged_T1$L_Edge_weight > 0 & Merged_T1$O_Edge_weight > 0) | 
       (Merged_T1$L_Edge_weight < 0 & Merged_T1$O_Edge_weight < 0)), 1, 0
    )
  )
)

#Summary Data Time 2 ######################
Merged_T2 <- merge(L_Edges_T2, O_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T2 <- merge(Merged_T2, Cov_Edges_T2, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T2$Recovery <- ifelse(
  !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
  (Merged_T2$L_Edge_weight != 0 & Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T2$O_Edge_weight) & !is.na(Merged_T2$Cov_Edge_weight) &
    (Merged_T2$O_Edge_weight != 0 & Merged_T2$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T2$L_Edge_weight) & !is.na(Merged_T2$O_Edge_weight) &
      ((Merged_T2$L_Edge_weight > 0 & Merged_T2$O_Edge_weight > 0) | 
       (Merged_T2$L_Edge_weight < 0 & Merged_T2$O_Edge_weight < 0)), 1, 0
    )
  )
)


#Summary Data Time 3 ######################
Merged_T3 <- merge(L_Edges_T3, O_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)
Merged_T3 <- merge(Merged_T3, Cov_Edges_T3, by.y = c("Source", "Sink", "Time"), all=TRUE)

Merged_T3$Recovery <- ifelse(
  !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
  (Merged_T3$L_Edge_weight != 0 & Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 3,
  ifelse(
    !is.na(Merged_T3$O_Edge_weight) & !is.na(Merged_T3$Cov_Edge_weight) &
    (Merged_T3$O_Edge_weight != 0 & Merged_T3$Cov_Edge_weight != 0), 2,
    ifelse(
      !is.na(Merged_T3$L_Edge_weight) & !is.na(Merged_T3$O_Edge_weight) &
      ((Merged_T3$L_Edge_weight > 0 & Merged_T3$O_Edge_weight > 0) | 
       (Merged_T3$L_Edge_weight < 0 & Merged_T3$O_Edge_weight < 0)), 1, 0
    )
  )
)


# Merge together
################################################################################
Merged_T100 <- rbind(Merged_T1, Merged_T2, Merged_T3)
Merged_T100$SampleSize <- 100

```



## 2.6 Graph Percent True Edges

Percent True Edges Recovered
```{r}
# Drop Source and Sink column and combine together
#################################################################
Merged_T1b <- Merged_T1 %>% dplyr::select(-Source, -Sink)
Merged_T20b <- Merged_T20 %>% dplyr::select(-Source, -Sink)
Merged_T50b <- Merged_T50 %>% dplyr::select(-Source, -Sink)
Merged_T75b <- Merged_T75 %>% dplyr::select(-Source, -Sink)
Merged_T100b <- Merged_T100 %>% dplyr::select(-Source, -Sink)

# Merge together
#################################################################
Subject_sens_data <- rbind(Merged_T1b, Merged_T20b, Merged_T50b, Merged_T75b, Merged_T100b)

#write.csv(Subject_sens_data,here("Output", "Subj_sens.csv"))
#Subject_sens_data_full <- read.csv(here("Output", "Subj_sens.csv"))

```


Time 1
```{r}
Subject_sens_data <- Subject_sens_data_full %>% filter(Time ==1)

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0)) %>%
  ungroup()

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0, na.rm = TRUE)) %>%
  ungroup()

Subject_sens_data <- merge(Subject_sens_data, Subject_sens_data2, by=("SampleSize"), all=TRUE)

# Percent True Edges Data
#################################################################
Percent_true <- Subject_sens_data  %>%
  group_by(SampleSize, Recovery, True_Edges) %>%
  summarise(Count = n()) %>%
  ungroup() %>%
  filter(Recovery != 0)

# Add the number of edges in all three data types to the LIMON vs Raw Speic-Easi counts
Percent_true <- Percent_true %>%
   group_by(SampleSize, True_Edges) %>%
   mutate(
     Count_3 = ifelse(Recovery == 3, Count, 0),
     Count = ifelse(Recovery == 1 | Recovery == 2, Count + sum(Count_3), Count)
   ) %>%
   dplyr::select(-Count_3)

# Create a dataframe with all combinations of SampleSize and Recovery
combinations <- expand.grid(SampleSize = unique(Percent_true$SampleSize), Recovery = c(1, 2, 3))
Percent_true <- merge(Percent_true, combinations, by.y=c("SampleSize", "Recovery"), all=TRUE)

Percent_true_1 <- Percent_true %>%
  group_by(SampleSize) %>%
  fill(True_Edges, .direction = "downup") %>%
  mutate(
    Count = ifelse(is.na(Count), Count[Recovery == 3][1], ifelse(is.na(Count), 0, Count))) %>%
  ungroup() %>%
  replace_na(list(Count = 0)) %>% 
  mutate(DataType = case_when(Recovery == 1 ~ "LIMON",
                          Recovery == 2 ~ "SPIEC-EASI",
                          Recovery == 3 ~ "Both"))


# Calculate the Percentage
Percent_true_1$Percent_true <- Percent_true_1$Count/Percent_true_1$True_Edges
Percent_true_1$Time <- 1
```



Time 2
```{r}
Subject_sens_data <- Subject_sens_data_full %>% filter(Time ==2)

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0)) %>%
  ungroup()

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0, na.rm = TRUE)) %>%
  ungroup()

Subject_sens_data <- merge(Subject_sens_data, Subject_sens_data2, by=("SampleSize"), all=TRUE)

# Percent True Edges Data
#################################################################
Percent_true <- Subject_sens_data  %>%
  group_by(SampleSize, Recovery, True_Edges) %>%
  summarise(Count = n()) %>%
  ungroup() %>%
  filter(Recovery != 0)

# Add the number of edges in all three data types to the LIMON vs Raw Speic-Easi counts
Percent_true <- Percent_true %>%
   group_by(SampleSize, True_Edges) %>%
   mutate(
     Count_3 = ifelse(Recovery == 3, Count, 0),
     Count = ifelse(Recovery == 1 | Recovery == 2, Count + sum(Count_3), Count)
   ) %>%
   dplyr::select(-Count_3)

# Create a dataframe with all combinations of SampleSize and Recovery
combinations <- expand.grid(SampleSize = unique(Percent_true$SampleSize), Recovery = c(1, 2, 3))
Percent_true <- merge(Percent_true, combinations, by.y=c("SampleSize", "Recovery"), all=TRUE)

Percent_true_2 <- Percent_true %>%
  group_by(SampleSize) %>%
  fill(True_Edges, .direction = "downup") %>%
  mutate(
    Count = ifelse(is.na(Count), Count[Recovery == 3][1], ifelse(is.na(Count), 0, Count))) %>%
  ungroup() %>%
  replace_na(list(Count = 0)) %>% 
  mutate(DataType = case_when(Recovery == 1 ~ "LIMON",
                          Recovery == 2 ~ "SPIEC-EASI",
                          Recovery == 3 ~ "Both"))


# Calculate the Percentage
Percent_true_2$Percent_true <- Percent_true_2$Count/Percent_true_2$True_Edges
Percent_true_2$Time <- 2
```



Time 3
```{r}
Subject_sens_data <- Subject_sens_data_full %>% filter(Time ==3)

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0)) %>%
  ungroup()

Subject_sens_data2 <- Subject_sens_data %>%
  group_by(SampleSize) %>%
  summarise(True_Edges = sum(O_Edge_weight != 0, na.rm = TRUE)) %>%
  ungroup()

Subject_sens_data <- merge(Subject_sens_data, Subject_sens_data2, by=("SampleSize"), all=TRUE)

# Percent True Edges Data
#################################################################
Percent_true <- Subject_sens_data  %>%
  group_by(SampleSize, Recovery, True_Edges) %>%
  summarise(Count = n()) %>%
  ungroup() %>%
  filter(Recovery != 0)

# Add the number of edges in all three data types to the LIMON vs Raw Speic-Easi counts
Percent_true <- Percent_true %>%
   group_by(SampleSize, True_Edges) %>%
   mutate(
     Count_3 = ifelse(Recovery == 3, Count, 0),
     Count = ifelse(Recovery == 1 | Recovery == 2, Count + sum(Count_3), Count)
   ) %>%
   dplyr::select(-Count_3)

# Create a dataframe with all combinations of SampleSize and Recovery
combinations <- expand.grid(SampleSize = unique(Percent_true$SampleSize), Recovery = c(1, 2, 3))
Percent_true <- merge(Percent_true, combinations, by.y=c("SampleSize", "Recovery"), all=TRUE)

Percent_true_3 <- Percent_true %>%
  group_by(SampleSize) %>%
  fill(True_Edges, .direction = "downup") %>%
  mutate(
    Count = ifelse(is.na(Count), Count[Recovery == 3][1], ifelse(is.na(Count), 0, Count))) %>%
  ungroup() %>%
  replace_na(list(Count = 0)) %>% 
  mutate(DataType = case_when(Recovery == 1 ~ "LIMON",
                          Recovery == 2 ~ "SPIEC-EASI",
                          Recovery == 3 ~ "Both"))


# Calculate the Percentage
Percent_true_3$Percent_true <- Percent_true_3$Count/Percent_true_3$True_Edges
Percent_true_3$Time <- 3
```




Merge and Graph the data
```{r}

# Data
#################################################################
Percent_true <- rbind(Percent_true_1,Percent_true_2,Percent_true_3)

# Calculate summary statistics
Summary_data <- Percent_true %>%
  group_by(SampleSize, DataType) %>%
  summarise(
    mean_percent_true = mean(Percent_true),
    sd_percent_true = sd(Percent_true),
    n = n()
  ) %>%
  mutate(
    se_percent_true = sd_percent_true / sqrt(n)
  )

# Graph
#################################################################
ggplot(Summary_data, aes(x = SampleSize, y = mean_percent_true, color = DataType)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = mean_percent_true - se_percent_true, 
                    ymax = mean_percent_true + se_percent_true), width = 0.2) +
  labs(x = "SampleSize", y = "Percent_true", color = "DataType") +
  xlim(10, 100) +
  ylim(0, 1) +
  xlab("Subject Sample Size") +
  ylab("Percent True Edges") +
  scale_color_manual(values = c("LIMON" = "orange", "SPIEC-EASI" = "blue", "Both" = "green")) +
  theme_minimal()

```



## 2.6 Graph Total Edges

Make Data frame for Total Edges per data Type by Time point
```{r}
# Time 1
#################################################################
Total_Edges_1 <- Subject_sens_data_full %>%
  filter(Time == 1) %>%
  group_by(SampleSize) %>%
  summarize(
    Count_L_Edge_weight = sum(!is.na(L_Edge_weight)),
    Count_O_Edge_weight = sum(!is.na(O_Edge_weight)),
    Count_Cov_Edge_weight = sum(!is.na(Cov_Edge_weight))
  )  %>%
  pivot_longer(cols = starts_with("Count"), names_to = "Counts_Column_Name", values_to = "Count")  %>%
  mutate(DataType = case_when(Counts_Column_Name == "Count_L_Edge_weight" ~ "LIMON",
                              Counts_Column_Name == "Count_O_Edge_weight" ~ "True",
                              Counts_Column_Name == "Count_Cov_Edge_weight" ~ "SPIEC-EASI"))
Total_Edges_1$Time <- 1

# Time 2
#################################################################
Total_Edges_2 <- Subject_sens_data_full %>%
  filter(Time == 2) %>%
  group_by(SampleSize) %>%
  summarize(
    Count_L_Edge_weight = sum(!is.na(L_Edge_weight)),
    Count_O_Edge_weight = sum(!is.na(O_Edge_weight)),
    Count_Cov_Edge_weight = sum(!is.na(Cov_Edge_weight))
  )  %>%
  pivot_longer(cols = starts_with("Count"), names_to = "Counts_Column_Name", values_to = "Count")  %>%
  mutate(DataType = case_when(Counts_Column_Name == "Count_L_Edge_weight" ~ "LIMON",
                              Counts_Column_Name == "Count_O_Edge_weight" ~ "True",
                              Counts_Column_Name == "Count_Cov_Edge_weight" ~ "SPIEC-EASI"))
Total_Edges_2$Time <- 2

# Time 3
#################################################################
Total_Edges_3 <- Subject_sens_data_full %>%
  filter(Time == 3) %>%
  group_by(SampleSize) %>%
  summarize(
    Count_L_Edge_weight = sum(!is.na(L_Edge_weight)),
    Count_O_Edge_weight = sum(!is.na(O_Edge_weight)),
    Count_Cov_Edge_weight = sum(!is.na(Cov_Edge_weight))
  )  %>%
  pivot_longer(cols = starts_with("Count"), names_to = "Counts_Column_Name", values_to = "Count")  %>%
  mutate(DataType = case_when(Counts_Column_Name == "Count_L_Edge_weight" ~ "LIMON",
                              Counts_Column_Name == "Count_O_Edge_weight" ~ "True",
                              Counts_Column_Name == "Count_Cov_Edge_weight" ~ "SPIEC-EASI"))
Total_Edges_3$Time <- 3
```





```{r}
# Merge Data
##################################################################
Total_Edges <- rbind(Total_Edges_1, Total_Edges_2, Total_Edges_3)

# Calculate summary statistics
##################################################################
Summary_data <- Total_Edges %>%
  group_by(SampleSize, DataType) %>%
  summarise(
    mean_edges = mean(Count),
    sd_edges = sd(Count),
    n = n()
  ) %>%
  mutate(
    se_edges = sd_edges / sqrt(n)
  )


# Graph
#################################################################
ggplot(Summary_data, aes(x = SampleSize, y = mean_edges, color = DataType)) +
  geom_line() +
  geom_point() +
    geom_errorbar(aes(ymin = mean_edges - se_edges, 
                    ymax = mean_edges + se_edges), width = 0.2) +
  labs(x = "SampleSize", y = "Count", color = "DataType") +
  xlim(10, 100) +
  xlab("Subject Sample Size") +
  ylab("Total Network Edges") +
  scale_color_manual(values = c("LIMON" = "orange", "SPIEC-EASI" = "blue", "True" = "darkgrey")) +
  theme_minimal()

```







